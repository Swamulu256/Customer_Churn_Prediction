ğŸ“Œ Project Overview

Customer churn is a critical problem for telecom companies. This project builds a robust, automated machine learning pipeline to analyze, preprocess, model, and predict customer churn using the Telco Customer Churn dataset.

The pipeline intelligently selects the best technique at every stage (missing values, encoding, scaling, balancing, feature selection, and modeling) based on data-driven evaluation.

ğŸ§  Key Highlights

ğŸ” Fully automated ML pipeline

ğŸ“Š Rich EDA & business-oriented visualizations

ğŸ§ª Technique selection instead of hard-coding

âš–ï¸ Handles class imbalance

ğŸ† Compares multiple ML models

ğŸ“ˆ Uses ROC-AUC for model selection

ğŸ’¾ Saves deployment-ready artifacts

ğŸ—‚ï¸ Project Structure
â”œâ”€â”€ main.py
â”œâ”€â”€ Visualization.py
â”œâ”€â”€ missing_values.py
â”œâ”€â”€ variable_transformation_technique.py
â”œâ”€â”€ outliers_techniques.py
â”œâ”€â”€ cat_to_num_Techniques.py
â”œâ”€â”€ Feature_Selection_Techniques.py
â”œâ”€â”€ Data_Balancing.py
â”œâ”€â”€ Model_techniques.py
â”œâ”€â”€ log_file.py
â”œâ”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv
â”œâ”€â”€ churn_artifacts.pkl
â”œâ”€â”€ scaler_path.pkl
â”œâ”€â”€ final_features.pkl
â””â”€â”€ README.md

ğŸ“Š Exploratory Data Analysis (EDA)

The following visualizations are generated automatically:

Gender vs Churn

Churn Distribution

Tenure vs Churn

Monthly Charges vs Churn

Senior Citizen & Gender vs Churn

Internet Service vs Gender

Contract Type vs Churn

Telecom Partner vs Churn

Payment Method vs Churn

ğŸ“Œ These plots help understand customer behavior and churn drivers before modeling.

ğŸ”„ Machine Learning Pipeline
1ï¸âƒ£ Data Loading & Preparation

Reads Telco churn dataset

Adds a synthetic telecom_partner feature

Converts TotalCharges to numeric

Encodes target variable (Churn: Yes â†’ 1, No â†’ 0)

Trainâ€“test split (80/20)

2ï¸âƒ£ Missing Value Handling

Multiple imputation techniques are evaluated:

Mean

Median

Mode

End-of-Distribution

Forward Fill / Backward Fill

Random Sampling

âœ… Best technique per column is selected automatically based on variance / missing reduction.

3ï¸âƒ£ Variable Transformation

Numerical features are transformed using:

Standard Scaling

MinMax Scaling

Robust Scaling

Log Transform

Power Transform

Box-Cox

Quantile Transform

ğŸ“‰ Transformation with minimum skewness is chosen per feature.

4ï¸âƒ£ Outlier Handling

Outliers are detected using IQR method and treated using:

Winsorization

Robust Scaling

Log Transform

No Treatment

ğŸ¯ The method leaving the fewest outliers is selected.

5ï¸âƒ£ Categorical Encoding

Categorical variables are encoded using:

Label Encoding

One-Hot Encoding

Frequency Encoding

Binary Encoding

Ordinal Encoding

ğŸ“Œ Encoding is chosen based on feature dimensionality efficiency.

6ï¸âƒ£ Feature Selection

Techniques evaluated:

Variance Threshold

Correlation Filter

SelectKBest

RFE

Lasso

Tree-based Selection

ğŸ† The technique selecting optimal minimum features is applied.
ğŸ“ Final selected features are saved as final_features.pkl.

7ï¸âƒ£ Data Balancing

Class imbalance is handled using:

No balancing

Random Over Sampling

Random Under Sampling

SMOTE

SMOTE-Tomek

SMOTE-ENN

ğŸ“Š Best method selected using F1-score (CV-based).

8ï¸âƒ£ Feature Scaling

Scaling techniques compared:

StandardScaler

MinMaxScaler

RobustScaler

MaxAbsScaler

Normalizer

ğŸ† Best scaler chosen using cross-validated F1-score and saved as scaler_path.pkl.

9ï¸âƒ£ Model Training & Evaluation

Models compared using ROC-AUC:

KNN

Naive Bayes

Logistic Regression

Decision Tree

Random Forest

SVM

XGBoost

ğŸ“ˆ ROC curves are plotted for all models.

ğŸ”§ Hyperparameter Tuning

Only the best performing model is tuned:

Logistic Regression â†’ GridSearchCV

Random Forest â†’ GridSearchCV

ğŸ† Final Output

âœ… Best trained model

âœ… Final feature list

âœ… Scaler

âœ… ROC-AUC performance

